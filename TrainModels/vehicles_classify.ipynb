{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 426880 entries, 0 to 426879\n",
      "Data columns (total 17 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   price         426880 non-null  int64  \n",
      " 1   year          425675 non-null  float64\n",
      " 2   manufacturer  409234 non-null  object \n",
      " 3   model         421603 non-null  object \n",
      " 4   condition     252776 non-null  object \n",
      " 5   cylinders     249202 non-null  object \n",
      " 6   fuel          423867 non-null  object \n",
      " 7   odometer      422480 non-null  float64\n",
      " 8   title_status  418638 non-null  object \n",
      " 9   transmission  424324 non-null  object \n",
      " 10  drive         296313 non-null  object \n",
      " 11  size          120519 non-null  object \n",
      " 12  type          334022 non-null  object \n",
      " 13  paint_color   296677 non-null  object \n",
      " 14  state         426880 non-null  object \n",
      " 15  lat           420331 non-null  float64\n",
      " 16  long          420331 non-null  float64\n",
      "dtypes: float64(4), int64(1), object(12)\n",
      "memory usage: 55.4+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd # تضمين المكتبة في المشروع\n",
    "\n",
    "data_frame = pd.read_csv('vehicles.csv') # قراءة الملف\n",
    "print('\\t\\tData info\\n')\n",
    "data_frame.info() # طباعة معلومات البيانات من حيث الأعمدة ونوع بياناتها وعدد القيم الغير فارغة\n",
    "print('=====================================================\\n\\t\\tData description\\n')\n",
    "data_frame.describe(include='all') # طباعة معلومات إحصائية عن البيانات"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 426880 entries, 0 to 426879\n",
      "Data columns (total 17 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   price         426880 non-null  float64\n",
      " 1   year          426880 non-null  float64\n",
      " 2   manufacturer  426880 non-null  object \n",
      " 3   model         426880 non-null  object \n",
      " 4   condition     426880 non-null  object \n",
      " 5   cylinders     426880 non-null  object \n",
      " 6   fuel          426880 non-null  object \n",
      " 7   odometer      426880 non-null  float64\n",
      " 8   title_status  426880 non-null  object \n",
      " 9   transmission  426880 non-null  object \n",
      " 10  drive         426880 non-null  object \n",
      " 11  size          426880 non-null  object \n",
      " 12  type          426880 non-null  object \n",
      " 13  paint_color   426880 non-null  object \n",
      " 14  state         426880 non-null  object \n",
      " 15  lat           426880 non-null  float64\n",
      " 16  long          426880 non-null  float64\n",
      "dtypes: float64(5), object(12)\n",
      "memory usage: 55.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# حذف العواميد الغير ضروية\n",
    "for column_name in ['id', 'url', 'region_url', 'county', 'image_url', 'description', 'posting_date', 'VIN', 'region']:\n",
    "  data_frame = data_frame.drop(column_name, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # تضمين مكتبة تفيدنا بالتعامل مع المصفوفات والأرقام في بايثون\n",
    "\n",
    "numerical_columns = ['odometer', 'lat', 'long', 'price', 'year']\n",
    "categorical_columns = ['manufacturer', 'condition', 'cylinders', 'fuel', 'title_status', 'transmission', 'drive', 'size', 'type', 'paint_color', 'model', 'state']\n",
    "\n",
    "data_frame.loc[data_frame['year'] % 1 != 0, 'year'] = np.nan\n",
    "\n",
    "for column_name in numerical_columns:\n",
    "    data_frame.loc[data_frame[column_name] < 0, column_name] = np.nan # استدبال القيم الأصغر من صفر بالقيمة nan\n",
    "    threshold = data_frame[column_name].std() * 2 # حساب العتبة المسموح بها فوق المتسوط الحسابي\n",
    "    max_value = data_frame[column_name].mean() + threshold # حساب القيمة العظمى المسموحة بالعمود\n",
    "    data_frame.loc[data_frame[column_name] > max_value, column_name] = max_value # استبدال القيم الأكبر من القيمة المنطقية العظمى بالقيمة العظمى\n",
    "    data_frame[column_name].fillna(data_frame[column_name].mean(), inplace=True) # استبدال القيم الفارغة بالمتوسط الحسابي\n",
    "\n",
    "for column_name in categorical_columns:\n",
    "    data_frame[column_name].fillna(data_frame[column_name].mode()[0], inplace=True) # استبدال القيم الفارغة بالمنوال\n",
    "\n",
    "data_frame.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder # تضمين المكتبة المسؤولة عن ترميز البيانات الفئوية\n",
    "\n",
    "label_encoders = {}\n",
    "for column_name in categorical_columns:\n",
    "    label_encoders[column_name] = LabelEncoder()\n",
    "    data_frame[column_name] = label_encoders[column_name].fit_transform(data_frame[column_name]) # ترميز البيانات واستبدالها ضمن إطار البيانات الحالي"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_frame.drop('type', axis=1)\n",
    "y = data_frame['type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "ax = plt.subplots(figsize=(6, 6))[1]\n",
    "\n",
    "cv = y.value_counts()\n",
    "\n",
    "original_labels = label_encoders['type'].classes_ # قراءة القيم الأصلية الفئوية للعمود نوع السيارة\n",
    "\n",
    "ax.pie(x=cv, labels= original_labels, autopct='%1.1f%%')\n",
    "ax.set_title('Original classes distribution', fontsize=14)\n",
    "plt.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "oversample = SMOTE()\n",
    "\n",
    "X, y = oversample.fit_resample(X, y)\n",
    "\n",
    "cv = y.value_counts()\n",
    "\n",
    "ax = plt.subplots(figsize=(6, 6))[1]\n",
    "ax.pie(x=cv, labels= original_labels, autopct='%1.1f%%')\n",
    "ax.set_title('New classes distribution', fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame = pd.concat([X, y], axis=1)\n",
    "print('\\t\\tData info\\n')\n",
    "data_frame.info()\n",
    "print('=====================================================\\n\\t\\tData description\\n')\n",
    "print(data_frame.describe())\n",
    "relation = X.corrwith(y, method='pearson')\n",
    "print('=====================================================\\n\\t\\tPearson relathion\\n')\n",
    "print(relation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column_name in [*categorical_columns, *numerical_columns]:\n",
    "    print(column_name, len(data_frame[column_name].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "columns_to_scale = ['odometer', 'lat', 'price', 'year']\n",
    "scaler = StandardScaler()\n",
    "data_frame[columns_to_scale] = scaler.fit_transform(data_frame[columns_to_scale])\n",
    "\n",
    "X = data_frame.drop('type', axis=1)\n",
    "y = data_frame['type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data for training and testing library\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression classifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# instance\n",
    "logisticRegressionModel = LogisticRegression(solver='sag')\n",
    "\n",
    "#start training\n",
    "logisticRegressionModel.fit(X_train, y_train)\n",
    "\n",
    "# calculate classification result with test data\n",
    "logisticRegression_y_pred = logisticRegressionModel.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate evaluation Criteria by model training result with testing result\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "logisticRegression_scores = {\n",
    "    'Accuracy': accuracy_score(y_test, logisticRegression_y_pred),\n",
    "    'Precision': precision_score(y_test, logisticRegression_y_pred, average='micro'),\n",
    "    'Recall': recall_score(y_test, logisticRegression_y_pred, average='micro'),\n",
    "    'F1': f1_score(y_test, logisticRegression_y_pred, average='micro')\n",
    "}\n",
    "\n",
    "for key in logisticRegression_scores:\n",
    "        logisticRegression_scores[key] = '{:.2f}'.format(100 * logisticRegression_scores[key])\n",
    "\n",
    "printString = \"\\t\\tLogistic Regression scores\\n\"\n",
    "for key in logisticRegression_scores:\n",
    "        printString += \"{:^15} |\".format(key)\n",
    "printString += \"\\n-------------------------------------------------------------------------------------\\n\"\n",
    "for key in logisticRegression_scores:\n",
    "    printString += \"{:^15} |\".format(logisticRegression_scores[key])\n",
    "print(printString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree Classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# instance\n",
    "decisionTreeModel = DecisionTreeClassifier()\n",
    "\n",
    "#start training\n",
    "decisionTreeModel.fit(X_train, y_train)\n",
    "\n",
    "# calculate classification result with test data\n",
    "decisionTree_y_pred = decisionTreeModel.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate evaluation Criteria by model training result with testing result\n",
    "decisionTree_scores = {\n",
    "    'Accuracy': accuracy_score(y_test, decisionTree_y_pred),\n",
    "    'Precision': precision_score(y_test, decisionTree_y_pred, average='micro'),\n",
    "    'Recall': recall_score(y_test, decisionTree_y_pred, average='micro'),\n",
    "    'F1': f1_score(y_test, decisionTree_y_pred, average='micro')\n",
    "}\n",
    "\n",
    "for key in decisionTree_scores:\n",
    "        decisionTree_scores[key] = '{:.2f}'.format(100 * decisionTree_scores[key])\n",
    "\n",
    "printString = \"\\t\\tDecision Tree scores\\n\"\n",
    "for key in decisionTree_scores:\n",
    "        printString += \"{:^15} |\".format(key)\n",
    "printString += \"\\n-------------------------------------------------------------------------------------\\n\"\n",
    "for key in decisionTree_scores:\n",
    "    printString += \"{:^15} |\".format(decisionTree_scores[key])\n",
    "print(printString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bayes classifier\n",
    "from sklearn.naive_bayes import CategoricalNB, GaussianNB\n",
    "# instance\n",
    "categorical_model = CategoricalNB(alpha=0)\n",
    "numerical_model = GaussianNB()\n",
    "\n",
    "# split data\n",
    "X_train_numerical = X_train[numerical_columns]\n",
    "X_train_categorical = X_train[[column_name for column_name in categorical_columns if column_name != 'type']]\n",
    "\n",
    "#start training\n",
    "categorical_model.fit(X_train_categorical, y_train)\n",
    "numerical_model.fit(X_train_numerical, y_train)\n",
    "\n",
    "# calculate classification result with test data\n",
    "X_test_numerical = X_test[numerical_columns]\n",
    "X_test_categorical = X_test[[column_name for column_name in categorical_columns if column_name != 'type']]\n",
    "categorical_pred = categorical_model.predict(X_test_categorical)\n",
    "numerical_pred = numerical_model.predict(X_test_numerical)\n",
    "\n",
    "combined_preds = np.vstack((categorical_pred, numerical_pred)).T\n",
    "bayes_y_pred = final_preds = np.apply_along_axis(lambda x: np.argmax(np.bincount(x)), axis=1, arr=combined_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate evaluation Criteria by model training result with testing result\n",
    "categorical_scores = {\n",
    "    'Accuracy': accuracy_score(y_test, categorical_pred),\n",
    "    'Precision': precision_score(y_test, categorical_pred, average='macro'),\n",
    "    'Recall': recall_score(y_test, categorical_pred, average='macro'),\n",
    "    'F1': f1_score(y_test, categorical_pred, average='macro')\n",
    "}\n",
    "numerical_scores = {\n",
    "    'Accuracy': accuracy_score(y_test, numerical_pred),\n",
    "    'Precision': precision_score(y_test, numerical_pred, average='macro'),\n",
    "    'Recall': recall_score(y_test, numerical_pred, average='macro'),\n",
    "    'F1': f1_score(y_test, numerical_pred, average='macro')\n",
    "}\n",
    "bayes_scores = {\n",
    "    'Accuracy': accuracy_score(y_test, bayes_y_pred),\n",
    "    'Precision': precision_score(y_test, bayes_y_pred, average='macro'),\n",
    "    'Recall': recall_score(y_test, bayes_y_pred, average='macro'),\n",
    "    'F1': f1_score(y_test, bayes_y_pred, average='macro')\n",
    "}\n",
    "\n",
    "for key in bayes_scores:\n",
    "        bayes_scores[key] = '{:.2f}'.format(100 * bayes_scores[key])\n",
    "\n",
    "printString = \"\\t\\tNaive Bayes scores\\n\"\n",
    "for key in bayes_scores:\n",
    "        printString += \"{:^15} |\".format(key)\n",
    "printString += \"\\n-------------------------------------------------------------------------------------\\n\"\n",
    "for key in bayes_scores:\n",
    "    printString += \"{:^15} |\".format(bayes_scores[key])\n",
    "print(printString)\n",
    "\n",
    "for key in categorical_scores:\n",
    "        categorical_scores[key] = '{:.2f}'.format(100 * categorical_scores[key])\n",
    "\n",
    "printString = \"\\n\\t\\tCategorical Naive Bayes scores\\n\"\n",
    "for key in categorical_scores:\n",
    "        printString += \"{:^15} |\".format(key)\n",
    "printString += \"\\n-------------------------------------------------------------------------------------\\n\"\n",
    "for key in categorical_scores:\n",
    "    printString += \"{:^15} |\".format(categorical_scores[key])\n",
    "print(printString)\n",
    "\n",
    "for key in numerical_scores:\n",
    "        numerical_scores[key] = '{:.2f}'.format(100 * numerical_scores[key])\n",
    "\n",
    "printString = \"\\n\\t\\tNumerical Naive Bayes scores\\n\"\n",
    "for key in numerical_scores:\n",
    "        printString += \"{:^15} |\".format(key)\n",
    "printString += \"\\n-------------------------------------------------------------------------------------\\n\"\n",
    "for key in numerical_scores:\n",
    "    printString += \"{:^15} |\".format(numerical_scores[key])\n",
    "print(printString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plot the distribution of all numerical columns\n",
    "for column_name in numerical_columns:\n",
    "    plt.hist(data_frame[column_name], bins=50)\n",
    "    plt.xlabel(column_name)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title(f'Distribution of {column_name}')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
